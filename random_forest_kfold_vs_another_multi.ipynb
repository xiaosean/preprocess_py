{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Clear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather \n",
    "import matplotlib.pyplot as plt  \n",
    "from time import time\n",
    "from mailerWithUtf8 import mail\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(df, out_filename):\n",
    "   # write to csv and no index\n",
    "    t0 = time()\n",
    "    df.to_csv(out_filename + \".csv\", index=False, encoding='utf-8')\n",
    "#     df.to_csv(out_filename + \".csv\", encoding='utf-8')\n",
    "    print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(train_df):\n",
    "    train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[\"Groups\"].unique())\n",
    "    train_numeric_y = le.transform(train_y)\n",
    "    rf = RandomForestClassifier(max_features='auto',\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1,\n",
    "                                n_estimators = 100)\n",
    "    param_grid = {\n",
    "                  \"min_samples_leaf\" : [10], \n",
    "                  \"min_samples_split\" : [2],\n",
    "                  \"max_depth\" : [25],\n",
    "                  \"n_estimators\": [100]}\n",
    "#     param_grid = {\n",
    "#                   \"min_samples_leaf\" : [10],                   \n",
    "#                   \"n_estimators\": [100]}\n",
    "    gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=1)\n",
    "    grid_clf = gs.fit(train_x, train_numeric_y)\n",
    "    clf = grid_clf.best_estimator_\n",
    "    \n",
    "    clf_info = str((\"Accuracy on training set: %f\" % gs.cv_results_[\"mean_test_score\"][0])) + '\\n'\n",
    "    # clf_info += str((\"Accuracy on test set: %f\" % clf.score(test_x, test_numeric_y))) + '\\n'\n",
    "    clf_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "#     print(clf_info)\n",
    "    important_dict = dict(zip(train_df.columns[:-1],clf.feature_importances_))\n",
    "    important_list = sorted(important_dict.items(), key=lambda x: x[1])\n",
    "    important_list.reverse()\n",
    "    clf_info += '\\n\\nFeature Importances\\n===================\\n'\n",
    "    for row in important_list:\n",
    "        clf_info += str(row) + \"\\n\"\n",
    "#         print(str(row))\n",
    "    feature_df = pd.DataFrame(important_list, columns = [\"COLUMN\", \"IMPORTANT_VALUE\"])\n",
    "    t0 = time()\n",
    "    feature_df.to_csv(out_path + out_filename + \"feature_important_descent.csv\", index=False)\n",
    "    #     print(\"time for output csv file: %.2f\" % (time()-t0))\n",
    "    cpy_dict = dict(important_list)\n",
    "    cpy_dict[\"Groups\"] = each_dir\n",
    "    feature_df = pd.DataFrame(cpy_dict, index = [0])\n",
    "    feature_df.to_csv(out_path + out_filename + \"feature_important_one_row.csv\", index=False)\n",
    "    accuracy_dict = {}\n",
    "    accuracy_dict[\"accuracy\"] = gs.cv_results_[\"mean_test_score\"][0]\n",
    "    accuracy_df = pd.DataFrame(accuracy_dict, index = [0])\n",
    "    accuracy_df.to_csv(out_path + out_filename + \"_accuracy.csv\", index=False)\n",
    "\n",
    "    predict_y = clf.predict(train_x)\n",
    "    cnf_matrix = confusion_matrix(train_numeric_y, predict_y )\n",
    "    group_encoder = []\n",
    "    for idx, row in enumerate(cnf_matrix):\n",
    "        current_group = str(le.inverse_transform(idx))\n",
    "        group_encoder.append(current_group)\n",
    "\n",
    "    #     idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "        idx_count_in_group = len(train_df[train_df[\"Groups\"] == current_group])\n",
    "\n",
    "        clf_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "        clf_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    #     print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    #     print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    #     print()\n",
    "    cnf_df = pd.DataFrame(cnf_matrix)\n",
    "    cnf_df.columns = group_encoder\n",
    "    cnf_df.index = group_encoder\n",
    "    cnf_df.to_csv(out_path + out_filename + \"confusion_matrix.csv\", index=False)\n",
    "    md_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "    with open(out_path + out_filename + 'readme.md', 'w+') as f:\n",
    "         f.write(md_info)\n",
    "    f.closed\n",
    "    return gs.cv_results_[\"mean_test_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_test(train_df):\n",
    "    train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[\"Groups\"].unique())\n",
    "    train_numeric_y = le.transform(train_y)\n",
    "    rf = RandomForestClassifier(max_features='auto',\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1,\n",
    "                                n_estimators = 100)\n",
    "#     param_grid = {\"criterion\" : [\"gini\"], \n",
    "#                   \"min_samples_leaf\" : [10], \n",
    "#                   \"min_samples_split\" : [2],\n",
    "#                   \"max_depth\" : [25],\n",
    "#                   \"n_estimators\": [100]}\n",
    "    param_grid = {\n",
    "                  \"min_samples_leaf\" : [10],                   \n",
    "                  \"n_estimators\": [100]}\n",
    "    gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=3)\n",
    "    grid_clf = gs.fit(train_x, train_numeric_y)\n",
    "    clf = grid_clf.best_estimator_\n",
    "   \n",
    "    return gs.cv_results_[\"mean_test_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InstantMessage-High',\n",
       " 'InstantMessage-SuperHigh',\n",
       " 'Lifestyle',\n",
       " 'No_significant_preference',\n",
       " 'No_significant_preference(instant_message)',\n",
       " 'Portal',\n",
       " 'Social-media']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/0814_sample_SMOTE/InstantMessage-High\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_InstantMessage-High_others.csv']\n",
      "['D:/0814_sample_SMOTE/InstantMessage-SuperHigh\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_InstantMessage-SuperHigh_others.csv']\n",
      "['D:/0814_sample_SMOTE/Lifestyle\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_Lifestyle_others.csv']\n",
      "['D:/0814_sample_SMOTE/No_significant_preference\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_No_significant_preference_others.csv']\n",
      "['D:/0814_sample_SMOTE/No_significant_preference(instant_message)\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_No_significant_preference(instant_message)_others.csv']\n",
      "['D:/0814_sample_SMOTE/Portal\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_Portal_others.csv']\n",
      "['D:/0814_sample_SMOTE/Social-media\\\\0814_marketing_with_picked_group11_numeric_max_min_sample_Social-media_others.csv']\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "path = \"D:/0814_sample_SMOTE/\"\n",
    "df = pd.DataFrame()\n",
    "for each_dir in os.listdir(path):\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        train_df = shuffle(train_df)\n",
    "        random_forest(train_df)\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.post(\n",
    "        \"https://api.mailgun.net/v3/sandboxe9bb891a60414f4bae93f2cc55daa963.mailgun.org/messages\",\n",
    "        auth=(\"api\", \"key-a007a22faf334a3510137b6cc03c21a6\"),\n",
    "        data={\"from\": \"Mailgun Sandbox <postmaster@sandboxe9bb891a60414f4bae93f2cc55daa963.mailgun.org>\",\n",
    "              \"to\": \"Toby <atch84@gmail.com>\",\n",
    "              \"subject\": \"Random Forest Finished\",\n",
    "              \"text\": \"Fucking Finished\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Send Mail\n",
      "User Email : a - DONE \n",
      "User Email : a - DONE \n",
      "User Email : 2 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 3 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : @ - DONE \n",
      "User Email : g - DONE \n",
      "User Email : m - DONE \n",
      "User Email : a - DONE \n",
      "User Email : i - DONE \n",
      "User Email : l - DONE \n",
      "User Email : . - DONE \n",
      "User Email : c - DONE \n",
      "User Email : o - DONE \n",
      "User Email : m - DONE \n",
      "Finish Send Mail\n"
     ]
    }
   ],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "test=mail()\n",
    "test.main(\"random forest finished\", \"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# check clip features accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0731_sample/\"\n",
    "accu_path = \"C:/Users/VIPLAB/Desktop/preprocess_py/clf_random_forest_model_kFold/\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        for accr_file in glob(accu_path + each_dir + \"/\" + \"*accuracy.csv\"):\n",
    "            accu_df = pd.read_csv(accr_file, error_bad_lines=False)\n",
    "            origin_accu = float(accu_df[\"accuracy\"][0])\n",
    "        print(\"origin_accu =\", origin_accu)\n",
    "\n",
    "        for features_file in glob(accu_path + each_dir + \"/\" + \"*descent.csv\"):\n",
    "            feature_df = pd.read_csv(features_file, error_bad_lines=False)\n",
    "        feature_list = list(feature_df[\"COLUMN\"])\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        for important_count in range(5, 100, 1):\n",
    "            temp_list = feature_list[:important_count].copy()\n",
    "            temp_list.append(\"Groups\")\n",
    "            simple_predict = float(random_forest_test(train_df[temp_list]))\n",
    "            print(\"use pre %d cols accurancy = %s\" % (important_count, simple_predict))\n",
    "            if(simple_predict - origin_accu > -0.01):\n",
    "                with open(accu_path + each_dir + \"/clip_feature.txt\", \"w\") as text_file:\n",
    "                    text_file.write(str(important_count))\n",
    "                break\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/\"\n",
    "df = pd.DataFrame()\n",
    "dir_list = [\"adult\"]\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)            \n",
    "        print(random_forest(train_df))\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_col = [\n",
    "    \"GENDER_CODE\",\n",
    "    \"DATA_USAGE_MB\",\n",
    "    \"P3M_AVG_DATA_USAGE_MB\",\n",
    "    \"L3M_DATA_USAGE_MB\",\n",
    "    \"IMEI_MKT_NAME\",\n",
    "    \"IMEI_MFG_NAME\",\n",
    "    \"AGE\",\n",
    "    \"DATA_INV_AMT\",\n",
    "    \"NET_INV_AMT\",\n",
    "    \"TENURE_SCV\",\n",
    "    \"L3M_AVG_NET_INV_AMT\",\n",
    "    \"DATA_RC_AMT\",\n",
    "    \"L3M_NET_INV_AMT\",\n",
    "    \"BILL_ZIP_CODE\",\n",
    "    \"ACTV_STORE_ID\",\n",
    "    \"P3M_MO_PSTN_DUR\",\n",
    "    \"P3M_MO_OFFNET_DUR\",\n",
    "    \"MOST_MT_DUR\",\n",
    "    \"MT_STM_AMT\",\n",
    "    \"VOICE_INV_AMT\",\n",
    "    \"Groups\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/\"\n",
    "df = pd.DataFrame()\n",
    "dir_list = [\"adult\"]\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "#         train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False, usecols= select_col)\n",
    "#         print(train_df.columns)\n",
    "#         break\n",
    "#         train_df = pd.read_csv(csv_file, error_bad_lines=False, usecols= select_col)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        print(random_forest(train_df))\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = \"clf_random_forest_model_kFold/adult_test_vs_others/\" + file_sample_count +\"/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_x, test_y = test_df.iloc[:, 0:-1].values, test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert y to numeric# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_df[\"Groups\"].unique())\n",
    "train_numeric_y = le.transform(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_numeric_y = le.transform(test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                            oob_score=True,\n",
    "                            random_state=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_estimators = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\" : [\"gini\"], \n",
    "              \"min_samples_leaf\" : [10], \n",
    "              \"min_samples_split\" : [2],\n",
    "              \"max_depth\" : [None],\n",
    "              \"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {\"criterion\" : [\"gini\"], \n",
    "#               \"min_samples_leaf\" : [10], \n",
    "#               \"min_samples_split\" : [2],\n",
    "# #               \"max_depth\" : [10],\n",
    "#               \"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_[\"mean_test_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(clf, out_path + out_filename + 'CLF.pkl') \n",
    "# clf = joblib.load('filename.pkl') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_info = str((\"Accuracy on training set: %f\" % gs.cv_results_[\"mean_test_score\"][0])) + '\\n'\n",
    "# clf_info += str((\"Accuracy on test set: %f\" % clf.score(test_x, test_numeric_y))) + '\\n'\n",
    "clf_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "print(clf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_numeric_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_dict = dict(zip(train_df.columns[:-1],clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list = sorted(important_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_info += '\\n\\nFeature Importances\\n===================\\n'\n",
    "for row in important_list:\n",
    "    clf_info += str(row) + \"\\n\"\n",
    "    print(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(important_list, columns = [\"COLUMN\", \"IMPORTANT_VALUE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "feature_df.to_csv(out_path + out_filename + \"feature_important_descent.csv\", index=False)\n",
    "print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# # cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# feature_df.to_csv(out_path + out_filename + \"feature_important_one_row.csv\", index=False)\n",
    "# print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_y = clf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnf_matrix = confusion_matrix(test_numeric_y, predict_y )\n",
    "cnf_matrix = confusion_matrix(train_numeric_y, predict_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "#     idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    idx_count_in_group = len(train_df[train_df[\"Groups\"] == current_group])\n",
    "\n",
    "    clf_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df = pd.DataFrame(cnf_matrix)\n",
    "cnf_df.columns = group_encoder\n",
    "cnf_df.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df.to_csv(out_path + out_filename + \"confusion_matrix.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "with open(out_path + out_filename + 'readme.md', 'w+') as f:\n",
    "     f.write(md_info)\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(clf.feature_importances_, 'o')  \n",
    "# for i in \n",
    "plt.xticks(range(train_x.shape[1]), train_df.columns[:-1], rotation=90)  \n",
    "plt.ylim(0, 1)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "mail_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "test=mail()\n",
    "test.main(\"clf_info finished\", mail_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check feature importances accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "limit_importances = 5\n",
    "for idx, feature in enumerate(important_list):\n",
    "    if(idx == limit_importances):\n",
    "        break\n",
    "\n",
    "    #     print(feature[0])\n",
    "    feature_cols.append(feature[0])\n",
    "feature_cols.append(\"Groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train_x = train_df[feature_cols].iloc[:, 0:-1].values\n",
    "feature_test_x = test_df[feature_cols].iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_feature = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_feature_clf = gs_feature.fit(feature_train_x, train_numeric_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_feature = grid_feature_clf.best_estimator_\n",
    "clf_feature_info = str((\"Accuracy on training set: %f\" % clf_feature.score(feature_train_x, train_numeric_y))) + '\\n'\n",
    "clf_feature_info += str((\"Accuracy on test set: %f\" % clf_feature.score(feature_test_x, test_numeric_y))) + '\\n'\n",
    "clf_feature_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "clf_feature_info += str(('feature selection numbers = %s' % str(limit_importances) + '\\n'\n",
    "\n",
    "print(clf_feature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_feature_y = clf_feature.predict(feature_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_numeric_y, predict_feature_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "    idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd = pd.DataFrame(cnf_matrix)\n",
    "cnf_pd.columns = group_encoder\n",
    "cnf_pd.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(698, 350) \n",
    "Beep(523, 150) \n",
    "Beep(415, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

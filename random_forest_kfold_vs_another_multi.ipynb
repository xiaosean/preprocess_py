{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Clear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather \n",
    "import matplotlib.pyplot as plt  \n",
    "from time import time\n",
    "from mailerWithUtf8 import mail\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(df, out_filename):\n",
    "   # write to csv and no index\n",
    "    t0 = time()\n",
    "    df.to_csv(out_filename + \".csv\", index=False, encoding='utf-8')\n",
    "#     df.to_csv(out_filename + \".csv\", encoding='utf-8')\n",
    "    print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_list = [\n",
    "            'all',\n",
    "            'No_ignificant_preference',\n",
    "            'No_ignificant_preference(instant_message)', \n",
    "            'Portal',\n",
    "            'InstantMessage-High',\n",
    "            'Game',\n",
    "            'InstantMessage-SuperHigh',\n",
    "            'Social-media',\n",
    "            'HomeLife',\n",
    "            'Adult', \n",
    "            'Map', \n",
    "            'Infrequent_User'\n",
    "           ]\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sample_count = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(train_df):\n",
    "    train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[\"Groups\"].unique())\n",
    "    train_numeric_y = le.transform(train_y)\n",
    "    rf = RandomForestClassifier(max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1,\n",
    "                                n_estimators = 100)\n",
    "#     param_grid = {\"criterion\" : [\"gini\"], \n",
    "#                   \"min_samples_leaf\" : [10], \n",
    "#                   \"min_samples_split\" : [2],\n",
    "#                   \"max_depth\" : [25],\n",
    "#                   \"n_estimators\": [100]}\n",
    "    param_grid = {\n",
    "                  \"min_samples_leaf\" : [10],                   \n",
    "                  \"n_estimators\": [100]}\n",
    "    gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=3)\n",
    "    grid_clf = gs.fit(train_x, train_numeric_y)\n",
    "    clf = grid_clf.best_estimator_\n",
    "    \n",
    "    clf_info = str((\"Accuracy on training set: %f\" % gs.cv_results_[\"mean_test_score\"][0])) + '\\n'\n",
    "    # clf_info += str((\"Accuracy on test set: %f\" % clf.score(test_x, test_numeric_y))) + '\\n'\n",
    "    clf_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "#     print(clf_info)\n",
    "    important_dict = dict(zip(train_df.columns[:-1],clf.feature_importances_))\n",
    "    important_list = sorted(important_dict.items(), key=lambda x: x[1])\n",
    "    important_list.reverse()\n",
    "    clf_info += '\\n\\nFeature Importances\\n===================\\n'\n",
    "    for row in important_list:\n",
    "        clf_info += str(row) + \"\\n\"\n",
    "#         print(str(row))\n",
    "    feature_df = pd.DataFrame(important_list, columns = [\"COLUMN\", \"IMPORTANT_VALUE\"])\n",
    "    t0 = time()\n",
    "    feature_df.to_csv(out_path + out_filename + \"feature_important_descent.csv\", index=False)\n",
    "    #     print(\"time for output csv file: %.2f\" % (time()-t0))\n",
    "    cpy_dict = dict(important_list)\n",
    "    cpy_dict[\"Groups\"] = each_dir\n",
    "    feature_df = pd.DataFrame(cpy_dict, index = [0])\n",
    "    feature_df.to_csv(out_path + out_filename + \"feature_important_one_row.csv\", index=False)\n",
    "    accuracy_dict = {}\n",
    "    accuracy_dict[\"accuracy\"] = gs.cv_results_[\"mean_test_score\"][0]\n",
    "    accuracy_df = pd.DataFrame(accuracy_dict, index = [0])\n",
    "    accuracy_df.to_csv(out_path + out_filename + \"_accuracy.csv\", index=False)\n",
    "\n",
    "    predict_y = clf.predict(train_x)\n",
    "    cnf_matrix = confusion_matrix(train_numeric_y, predict_y )\n",
    "    group_encoder = []\n",
    "    for idx, row in enumerate(cnf_matrix):\n",
    "        current_group = str(le.inverse_transform(idx))\n",
    "        group_encoder.append(current_group)\n",
    "\n",
    "    #     idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "        idx_count_in_group = len(train_df[train_df[\"Groups\"] == current_group])\n",
    "\n",
    "        clf_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "        clf_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    #     print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    #     print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    #     print()\n",
    "    cnf_df = pd.DataFrame(cnf_matrix)\n",
    "    cnf_df.columns = group_encoder\n",
    "    cnf_df.index = group_encoder\n",
    "    cnf_df.to_csv(out_path + out_filename + \"confusion_matrix.csv\", index=False)\n",
    "    md_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "    with open(out_path + out_filename + 'readme.md', 'w+') as f:\n",
    "         f.write(md_info)\n",
    "    f.closed\n",
    "    return gs.cv_results_[\"mean_test_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/all\\\\0729_marketing_with_picked_group11_numeric_max_min_sample_all_0.csv']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d3fc86f42600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mout_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLASSIFIER\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mCURRENT_MODE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_csvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mout_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLASSIFIER\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mCURRENT_MODE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mout_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"clf_random_forest_model_kFold/\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0meach_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1719\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1720\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1721\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:15629)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m     \"\"\"\n\u001b[0;32m    739\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/\"\n",
    "df = pd.DataFrame()\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        random_forest(train_df)\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Send Mail\n",
      "User Email : a - DONE \n",
      "User Email : a - DONE \n",
      "User Email : 2 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 3 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : @ - DONE \n",
      "User Email : g - DONE \n",
      "User Email : m - DONE \n",
      "User Email : a - DONE \n",
      "User Email : i - DONE \n",
      "User Email : l - DONE \n",
      "User Email : . - DONE \n",
      "User Email : c - DONE \n",
      "User Email : o - DONE \n",
      "User Email : m - DONE \n",
      "Finish Send Mail\n"
     ]
    }
   ],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "test=mail()\n",
    "test.main(\"random forest finished\", \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/adult\\\\0729_marketing_with_picked_group11_numeric_max_min_sample_Adult_others_0.csv']\n",
      "0.683820435331\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/\"\n",
    "df = pd.DataFrame()\n",
    "dir_list = [\"adult\"]\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)            \n",
    "        print(random_forest(train_df))\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_col = [\n",
    "    \"GENDER_CODE\",\n",
    "    \"DATA_USAGE_MB\",\n",
    "    \"P3M_AVG_DATA_USAGE_MB\",\n",
    "    \"L3M_DATA_USAGE_MB\",\n",
    "    \"IMEI_MKT_NAME\",\n",
    "    \"IMEI_MFG_NAME\",\n",
    "    \"AGE\",\n",
    "    \"DATA_INV_AMT\",\n",
    "    \"NET_INV_AMT\",\n",
    "    \"TENURE_SCV\",\n",
    "    \"L3M_AVG_NET_INV_AMT\",\n",
    "    \"DATA_RC_AMT\",\n",
    "    \"L3M_NET_INV_AMT\",\n",
    "    \"BILL_ZIP_CODE\",\n",
    "    \"ACTV_STORE_ID\",\n",
    "    \"P3M_MO_PSTN_DUR\",\n",
    "    \"P3M_MO_OFFNET_DUR\",\n",
    "    \"MOST_MT_DUR\",\n",
    "    \"MT_STM_AMT\",\n",
    "    \"VOICE_INV_AMT\",\n",
    "    \"Groups\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/adult\\\\0729_marketing_with_picked_group11_numeric_max_min_sample_Adult_others_0.csv']\n",
      "0.690275811943\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0730_sample/\"\n",
    "df = pd.DataFrame()\n",
    "dir_list = [\"adult\"]\n",
    "for each_dir in dir_list:\n",
    "    all_csvs = glob(path + each_dir + \"/\" + \"*.csv\")\n",
    "    CLASSIFIER = \"RANDOM_FOREST\"\n",
    "    CURRENT_MODE = each_dir\n",
    "    print(all_csvs)\n",
    "    out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'\n",
    "    for csv_file in all_csvs:\n",
    "#         train_df = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "        train_df = pd.read_csv(csv_file, error_bad_lines=False, usecols= select_col)\n",
    "#         print(train_df.columns)\n",
    "#         break\n",
    "#         train_df = pd.read_csv(csv_file, error_bad_lines=False, usecols= select_col)\n",
    "        out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'                \n",
    "        out_path = \"clf_random_forest_model_kFold/\"+ each_dir + \"/\" + csv_file[-5:-6] +\"/\"\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        print(random_forest(train_df))\n",
    "#         print(each_dir, \"highest accuracy\", csv_file[-5:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = \"clf_random_forest_model_kFold/adult_test_vs_others/\" + file_sample_count +\"/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_x, test_y = test_df.iloc[:, 0:-1].values, test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert y to numeric# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_df[\"Groups\"].unique())\n",
    "train_numeric_y = le.transform(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_numeric_y = le.transform(test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                            oob_score=True,\n",
    "                            random_state=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_estimators = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\" : [\"gini\"], \n",
    "              \"min_samples_leaf\" : [10], \n",
    "              \"min_samples_split\" : [2],\n",
    "              \"max_depth\" : [None],\n",
    "              \"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {\"criterion\" : [\"gini\"], \n",
    "#               \"min_samples_leaf\" : [10], \n",
    "#               \"min_samples_split\" : [2],\n",
    "# #               \"max_depth\" : [10],\n",
    "#               \"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_[\"mean_test_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(clf, out_path + out_filename + 'CLF.pkl') \n",
    "# clf = joblib.load('filename.pkl') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_info = str((\"Accuracy on training set: %f\" % gs.cv_results_[\"mean_test_score\"][0])) + '\\n'\n",
    "# clf_info += str((\"Accuracy on test set: %f\" % clf.score(test_x, test_numeric_y))) + '\\n'\n",
    "clf_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "print(clf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_numeric_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_dict = dict(zip(train_df.columns[:-1],clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list = sorted(important_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_info += '\\n\\nFeature Importances\\n===================\\n'\n",
    "for row in important_list:\n",
    "    clf_info += str(row) + \"\\n\"\n",
    "    print(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(important_list, columns = [\"COLUMN\", \"IMPORTANT_VALUE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "feature_df.to_csv(out_path + out_filename + \"feature_important_descent.csv\", index=False)\n",
    "print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# # cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# feature_df.to_csv(out_path + out_filename + \"feature_important_one_row.csv\", index=False)\n",
    "# print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_y = clf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnf_matrix = confusion_matrix(test_numeric_y, predict_y )\n",
    "cnf_matrix = confusion_matrix(train_numeric_y, predict_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "#     idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    idx_count_in_group = len(train_df[train_df[\"Groups\"] == current_group])\n",
    "\n",
    "    clf_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df = pd.DataFrame(cnf_matrix)\n",
    "cnf_df.columns = group_encoder\n",
    "cnf_df.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_df.to_csv(out_path + out_filename + \"confusion_matrix.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "with open(out_path + out_filename + 'readme.md', 'w+') as f:\n",
    "     f.write(md_info)\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(clf.feature_importances_, 'o')  \n",
    "# for i in \n",
    "plt.xticks(range(train_x.shape[1]), train_df.columns[:-1], rotation=90)  \n",
    "plt.ylim(0, 1)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "mail_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "test=mail()\n",
    "test.main(\"clf_info finished\", mail_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check feature importances accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "limit_importances = 5\n",
    "for idx, feature in enumerate(important_list):\n",
    "    if(idx == limit_importances):\n",
    "        break\n",
    "\n",
    "    #     print(feature[0])\n",
    "    feature_cols.append(feature[0])\n",
    "feature_cols.append(\"Groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train_x = train_df[feature_cols].iloc[:, 0:-1].values\n",
    "feature_test_x = test_df[feature_cols].iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_feature = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_feature_clf = gs_feature.fit(feature_train_x, train_numeric_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_feature = grid_feature_clf.best_estimator_\n",
    "clf_feature_info = str((\"Accuracy on training set: %f\" % clf_feature.score(feature_train_x, train_numeric_y))) + '\\n'\n",
    "clf_feature_info += str((\"Accuracy on test set: %f\" % clf_feature.score(feature_test_x, test_numeric_y))) + '\\n'\n",
    "clf_feature_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "clf_feature_info += str(('feature selection numbers = %s' % str(limit_importances) + '\\n'\n",
    "\n",
    "print(clf_feature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_feature_y = clf_feature.predict(feature_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_numeric_y, predict_feature_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "    idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd = pd.DataFrame(cnf_matrix)\n",
    "cnf_pd.columns = group_encoder\n",
    "cnf_pd.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(698, 350) \n",
    "Beep(523, 150) \n",
    "Beep(415, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

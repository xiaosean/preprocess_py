{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_csv_list(target_path):\n",
    "    return [f for f in listdir(target_path) if isfile(join(target_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    logger.info(\"start read filename %s\" % filename) #写入错误日志\n",
    "\n",
    "    # read revise csv file and print cost time\n",
    "    t0 = time.time()\n",
    "    df = pd.read_csv(filename, error_bad_lines=False)\n",
    "    write_to_log(\"time for read csv file: %.2f\" % (time.time()-t0))\n",
    "    logger.info(\"time for read csv file: %.2f\" % (time.time()-t0)) #写入错误日志\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_date_column(df):\n",
    "    # we don't use VOICE_DATE/VOICE_MONTH bcz it is a monthly data\n",
    "    if(\"VOICE_DATE\" in df.columns):\n",
    "        df = df.drop('VOICE_DATE', 1)\n",
    "#         print(\"Drop VOICE_DATE\")\n",
    "    if(\"VOICE_MONTH\" in df.columns):\n",
    "        df = df.drop('VOICE_MONTH', 1)\n",
    "#         print(\"Drop VOICE_MONTH\")\n",
    "    if(\"DATA_MONTH\" in df.columns):\n",
    "        df = df.drop('DATA_MONTH', 1)\n",
    "#         print(\"Drop DATA_MONTH\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(df, out_filename):\n",
    "    logger.info(\"start save dataframe %s\" % filename) #写入错误日志\n",
    "\n",
    "   # write to csv and no index\n",
    "    t0 = time.time()\n",
    "    # aggr_df.to_csv(out_filename + \".csv\", index=False, encoding='utf-8')\n",
    "    df.to_csv(out_filename + \".csv\", encoding='utf-8')\n",
    "#     print(\"time for output csv file: %.2f\" % (time.time()-t0))\n",
    "    write_to_log(\"time for output csv file: %.2f\" % (time.time()-t0))\n",
    "    logger.info(\"time for output csv file: %.2f\" % (time.time()-t0)) #写入错误日志\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_table_path():\n",
    "    try:\n",
    "        logger.info(\"read preprocess_path_file.txt\") #写入错误日志\n",
    "        with open('./preprocess_path_file.txt') as f:\n",
    "            read_data = f.read()\n",
    "            read_data = read_data.replace(\"\\r\",\"\")\n",
    "            read_data = read_data.replace('\"',\"\")\n",
    "            read_data = read_data.replace(\"\\n\",\"\")\n",
    "            logger.info(\"txt split by ,\") #写入错误日志\n",
    "            table_list = read_data.split(\",\")\n",
    "            table_dict = {}\n",
    "            logger.info(\"load dict\") #写入错误日志\n",
    "            for table in table_list:\n",
    "                table_name, table_path = table.split(\"=\")\n",
    "                table_dict[table_name] = table_path\n",
    "            return table_dict\n",
    "    except Exception as e:\n",
    "        logger.error(e) #写入错误日志\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg):\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(time.time()))\n",
    "    with open(\"log.txt\", \"a\") as log_file:\n",
    "        log_file.write(current_time + \"\\t\" + msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logger config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "import logging\n",
    "import os\n",
    "# create logger\n",
    "LOG_DIR = \"LOG\"\n",
    "if not os.path.exists(os.path.join(LOG_DIR)):\n",
    "    os.makedirs(LOG_DIR)\n",
    "log_path = os.path.join(\".\",LOG_DIR, \"logging.log\")\n",
    "\n",
    "logger_name = \"test\"\n",
    "logger = logging.getLogger(logger_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create file handler\n",
    "fh = logging.FileHandler(log_path)\n",
    "fh.setLevel(logging.WARN)\n",
    "\n",
    "# create formatter\n",
    "fmt = \"%(asctime)-15s %(levelname)s %(filename)s %(lineno)d %(process)d %(message)s\"\n",
    "datefmt = \"%a %d %b %Y %H:%M:%S\"\n",
    "formatter = logging.Formatter(fmt, datefmt)\n",
    "\n",
    "# add handler and formatter to logger\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date_aggregate.py\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Date_aggregate.py\")\n",
    "logger.info(\"Start Date_aggregate.py\")\n",
    "logger.info(\"Date_csv_config\")\n",
    "write_to_log(\"Start Date_aggregate.py\")\n",
    "write_to_log(\"Start load path configure\")\n",
    "table_dict = get_table_path()\n",
    "NEED_AGGR_CSV_PATH = table_dict[\"NEED_AGGR_CSV_PATH\"]\n",
    "month = table_dict[\"MONTH\"]\n",
    "write_to_log(\"Finish load path configure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start connect ODBC\")\n",
    "try:\n",
    "    con = pyodbc.connect('Driver=Teradata;DBCName=10.68.64.141;UID=V_CSM;PWD=qazwsx')\n",
    "    con.setencoding(encoding = 'utf-8')\n",
    "except Exception as e:\n",
    "    logger.error(e) #写入错误日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set configure\n",
    "# path = \"../DATA_FULL/\"\n",
    "# path = \"./CDR_MONTHLY/\"\n",
    "# path = NEED_AGGR_CSV_PATH\n",
    "# filename = \"dm_subscr_moc_mly_COMPLETED_revise_month_4\"\n",
    "# relative_filename = path + filename + \".csv\"\n",
    "logger.info(\"check out path\")\n",
    "\n",
    "out_path = \"./CDR_MONTHLY_AGGR/\"\n",
    "if not os.path.exists(out_path):\n",
    "    logger.info(\"no dir -> CDR_MONTHLY_AGGR  make a dir\")\n",
    "    print(\"no dir -> CDR_MONTHLY_AGGR  make a dir\")\n",
    "    os.mkdir(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for filename in file_csv_list(path):\n",
    "#     if \".csv\" in filename:\n",
    "try:\n",
    "    month_col_name = \"DATA_MONTH\"\n",
    "    query_str = \"sel * from CSM_PROJECT.\" + \"dm_subscr_moc_mly\"\n",
    "    query_where = ' where extract(month from DATA_MONTH) = ' + month\n",
    "    # filename_none_postfix = filename[:-4]\n",
    "    out_filename =  out_path + \"dm_subscr_moc_mly_COMPLETED_month\"\n",
    "    # df = read_csv(path + filename)\n",
    "    logger.info(\"QUERY STR => %s\" % query_str + query_where)\n",
    "    logger.info(\"START QUERY => %s\" % query_str + query_where)\n",
    "    df = pd.read_sql(query_str + query_where, con)\n",
    "    # df = remove_date_column(df)\n",
    "    logger.info(\"START groupby MINING_DW_SUBSCR_NO sum\")\n",
    "    df = df.groupby('MINING_DW_SUBSCR_NO').sum()\n",
    "    save_dataframe(df, out_filename)\n",
    "except Exception as e:\n",
    "    logger.error(e) #写入错误日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    month_col_name = \"DATA_MONTH\"\n",
    "    query_str = \"sel * from CSM_PROJECT.\" + \"dm_subscr_mtc_mly\"\n",
    "    query_where = ' where extract(month from DATA_MONTH) = ' + month\n",
    "    # filename_none_postfix = filename[:-4]\n",
    "    out_filename =  out_path + \"dm_subscr_mtc_mly_COMPLETED_month\"\n",
    "    logger.info(\"QUERY STR => %s\" % query_str + query_where)\n",
    "    logger.info(\"START QUERY => %s\" % query_str + query_where)\n",
    "\n",
    "    df = pd.read_sql(query_str + query_where, con)\n",
    "    # df = read_csv(path + filename)\n",
    "    # df = remove_date_column(df)\n",
    "    logger.info(\"START groupby MINING_DW_SUBSCR_NO sum\")\n",
    "    df = df.groupby('MINING_DW_SUBSCR_NO').sum()\n",
    "    save_dataframe(df, out_filename)\n",
    "except Exception as e:\n",
    "    logger.error(e) #写入错误日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Date_aggregate.py\n"
     ]
    }
   ],
   "source": [
    "print(\"Finish Date_aggregate.py\")\n",
    "write_to_log(\"Finish Date_aggregate.py\")\n",
    "logger.info(\"Finish Date_aggregate.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

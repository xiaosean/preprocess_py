{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_table_path():\n",
    "    with open('./preprocess_path_file.txt') as f:\n",
    "        read_data = f.read()\n",
    "        read_data = read_data.replace(\"\\r\",\"\")\n",
    "        read_data = read_data.replace('\"',\"\")\n",
    "        read_data = read_data.replace(\"\\n\",\"\")\n",
    "    table_list = read_data.split(\",\")\n",
    "    table_dict = {}\n",
    "    for table in table_list:\n",
    "        table_name, table_path = table.split(\"=\")\n",
    "        table_dict[table_name] = table_path\n",
    "    return table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg):\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(time.time()))\n",
    "    with open(\"log.txt\", \"a\") as log_file:\n",
    "        log_file.write(current_time + \"\\t\" + msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start marketing_filter_columns.py\n"
     ]
    }
   ],
   "source": [
    "print(\"start marketing_filter_columns.py\")\n",
    "write_to_log(\"start marketing_filter_columns.py\")\n",
    "con = pyodbc.connect('Driver=Teradata;DBCName=10.68.64.141;UID=V_CSM;PWD=qazwsx')\n",
    "con.setencoding(encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load path configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"Start load path configure\")\n",
    "table_dict = get_table_path()\n",
    "DATA_MONTH = table_dict[\"DATA_MONTH\"]\n",
    "MDS_FILE = table_dict[\"MDS_TABLE\"]\n",
    "TELEGRAM_MT_FILE = table_dict[\"TELEGRAM_CDR_MT_AGGR_FILE\"]\n",
    "TELEGRAM_MO_FILE = table_dict[\"TELEGRAM_CDR_MO_AGGR_FILE\"]\n",
    "CWC_FILE = table_dict[\"CWC_TABLE\"]\n",
    "GROUP_ID_FILE = table_dict[\"GROUP_ID_FILE\"]\n",
    "OUT_FILENAME = table_dict[\"OUT_FILENAME\"]\n",
    "month = table_dict[\"MONTH\"]\n",
    "year = table_dict[\"YEAR\"]\n",
    "write_to_log(\"Finish load path configure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA_MONTH=\"201704\",\n",
    "# MDS_TABLE=\"D:/NEW_DATA_FULL_10_6/MDS_MULTI_PTYCBU_1_4.txt\",\n",
    "# TELEGRAM_CDR_MT_AGGR_FILE=\"D:/0725_preprocess_dat/CDR_MONTHLY_AGGR/dm_subscr_mtc_mly_COMPLETED_revise_month_4.csv\",\n",
    "# TELEGRAM_CDR_MO_AGGR_FILE=\"D:/0725_preprocess_dat/CDR_MONTHLY_AGGR/dm_subscr_moc_mly_COMPLETED_revise_month_4.csv\",\n",
    "# CWC_TABLE=\"D:/NEW_DATA_FULL_2017_6_16/CWC_CATG_CNT_COMPLETED.txt\",\n",
    "# GROUP_ID_FILE=\"./Groups_ID_multi_1008.csv\",\n",
    "# OUT_FILENAME=\"mrk_picked_with_group_id.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read csv file and print cost time\n",
    "t0 = time.time()\n",
    "query_str = \"sel * from CSM_PROJECT.\" + \"MDS_ACTIVE_MLY_567\"\n",
    "query_where = ' where extract(month from DATA_MONTH) = ' + month + \" AND SUBSCR_STATUS_CODE = \\'A\\' AND RPS_NAME = \\'CONSUMER MOBILITY\\' AND PTY_CBU_PO_CNT = 1\"\n",
    "# query_where = ' where extract(month from DATA_MONTH) = ' + month\n",
    "query_sample = \" sample 10\"\n",
    "# df1 = pd.read_sql(query_str, con)\n",
    "df = pd.read_sql(query_str + query_where + query_sample, con)\n",
    "# df = pd.read_csv(MDS_FILE, sep  = ',', error_bad_lines=False, nrows = 1)\n",
    "\n",
    "\n",
    "\n",
    "write_to_log(\"time for read csv: %.2f\" % (time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving money id bcz it will merge group\n",
    "# MINING_DW_SUBSCR_NO\n",
    "# 因為之後telegram的會併入新的表 原本的有問題\n",
    "telegram_str= \"\"\"\n",
    "MOC_FET_DUR\n",
    "MOC_TWM_DUR\n",
    "MOC_CHM_DUR\n",
    "MOC_OTH_DUR\n",
    "MOC_PSTN_DUR\n",
    "MTC_FET_DUR\n",
    "MTC_TWM_DUR\n",
    "MTC_CHM_DUR\n",
    "MTC_PSTN_DUR\n",
    "\"\"\"\n",
    "drop_str = \"\"\"\n",
    "CURR_SUBSCR_ID\n",
    "DW_PARTY_ID\n",
    "DATA_MONTH_RPT_TEMP1\n",
    "DATA_MONTH_RPT_TEMP2\n",
    "DATA_MONTH_RPT\n",
    "GA_DATE\n",
    "CHURN_IND\n",
    "CHURN_TYPE\n",
    "INACTV_DATE\n",
    "MKT_CHURN_DATE\n",
    "SUSPEND_IND\n",
    "TARGET_OPR_ID\n",
    "TEMP_INACTV_DATE\n",
    "RPS_NAME\n",
    "SUBSCR_STATUS_CODE\n",
    "BILL_DISTRICT_NAME\n",
    "CHURN_INDEX\n",
    "IMEI_SMART_OS_FLAG\n",
    "ACTV_CHANNEL_NAME\n",
    "SHIPMENT_CHANNEL_ID\n",
    "SHIPMENT_CHANNEL_CODE\n",
    "SHIPMENT_CHANNEL_NAME\n",
    "CCI_CHG_DATE\n",
    "SEGMENT_NAME\n",
    "NP_IN_DATE\n",
    "BONDING_FLAG\n",
    "CHURN_WELCOME_STAGE\n",
    "PTY_NP_IN_IND\n",
    "PTY_NP_OUT_IND\n",
    "RENEW_APPLY_DATE\n",
    "MDS_ELIGIBLE_FLAG\n",
    "PROM_BUNDLE_VRP\n",
    "PROM_BUNDLE_DRP\n",
    "PROM_CURR_PROM_NAME\n",
    "PROM_CURR_SYS_MODEL_IND\n",
    "PROM_DEVICE_TYPE\n",
    "PROM_DEVICE_BRAND\n",
    "PROM_DEVICE_OS\n",
    "PROM_DEVICE_MODEL\n",
    "PROM_ACTV_PROM_CODE\n",
    "PROM_ACTV_PROM_NAME\n",
    "PROM_ACTV_PROM_CATG\n",
    "PROM_CURR_APPLY_DATE\n",
    "PROM_CURR_START_DATE\n",
    "PROM_CURR_END_DATE\n",
    "PROM_CURR_CONTR_EXP_DATE\n",
    "L1M_PROM_CODE\n",
    "L1M_PROM_NAME\n",
    "L1M_PROM_COMMIT_MONTHS\n",
    "CURR_PROM_TTL_CMF\n",
    "CURR_PROM_CONTRACT_PERIOD\n",
    "L1M_PROM_TTL_CMF\n",
    "L1M_PROM_CONTRACT_PERIOD\n",
    "DUM_PROM_CODE\n",
    "GPRS_CAP_IND\n",
    "BEST_VRP_DESC\n",
    "BEST_DRP_DESC\n",
    "SERVICE_APPLY_MOVIE_FLAG\n",
    "SERVICE_APPLY_OMUSIC_FLAG\n",
    "SERVICE_APPLY_READING_FLAG\n",
    "HS_LEASE_FEATURE_START_DATE\n",
    "HS_LEASE_FEATURE_END_DATE\n",
    "HS_LEASE_CONTR_NAME\n",
    "HS_LEASE_CONTR_START_DATE\n",
    "HS_LEASE_CONTR_END_DATE\n",
    "SMS30_FLAG\n",
    "CURR_DATA_BILL_PLAN_START_DATE\n",
    "CURR_DATA_BILL_PLAN_END_DATE\n",
    "PRE_DATA_BILL_PLAN_ID\n",
    "PRE_DATA_BILL_PLAN_NAME\n",
    "PRE_DATA_BILL_PLAN_START_DATE\n",
    "PRE_DATA_BILL_PLAN_END_DATE\n",
    "DATA_BOOSTER_CURR_START_DATE\n",
    "LIM_BILL_PLAN_NAME\n",
    "L1M_DATA_BILL_PLAN_NAME\n",
    "CURR_BILL_PLAN_START_DATE\n",
    "EVER_PSTN_FEATURE_START_DATE\n",
    "EVER_PSTN_FEATURE_END_DATE\n",
    "EVER_PSTN_MONTH_APPLY_CANCEL_FLAG\n",
    "DISC_TYPE_AM_IND\n",
    "DISC_TYPE_AW_IND\n",
    "DISC_TYPE_AD_IND\n",
    "DISC_TYPE_DS_IND\n",
    "DISC_TYPE_DM_IND\n",
    "DISC_TYPE_DB_IND\n",
    "DISC_TYPE_DO_IND\n",
    "DISC_TYPE_DR_IND\n",
    "DISC_TYPE_DU_IND\n",
    "DISC_TYPE_DC_IND\n",
    "DISC_TYPE_DP_IND\n",
    "VIP_EXPIRY_DATE\n",
    "VIP_BEFORE_EXP_MONTH\n",
    "VIP_MSISDN_CHG_IND\n",
    "PAY_PENALTY_DATE\n",
    "DIRECT_STORE_PYMT_IND\n",
    "CVS_PYMT_IND\n",
    "VIRTUAL_CHANNEL_PYMT_IND\n",
    "L3M_DIRECT_STORE_PYMT_IND\n",
    "L3M_CVS_PYMT_IND\n",
    "L3M_VIRTUAL_CHANNEL_PYMT_IND\n",
    "HG_SEGMENT\n",
    "P6M_MO_ONNET_CNT\n",
    "P6M_MO_ONNET_DUR\n",
    "P6M_MO_OFFNET_CNT\n",
    "P6M_MO_OFFNET_DUR\n",
    "P6M_MO_PSTN_CNT\n",
    "P6M_MO_PSTN_DUR\n",
    "L1M_CHANNEL_CHURN_INDEX\n",
    "RETAIL_STORE_CHURN_FLAG\n",
    "RETAIL_STORE_CHURN_SRV_DATE\n",
    "RETAIL_STORE_CHURN_DEPUTY_FALG\n",
    "RETAIL_STORE_CHURN_STOP_REASON\n",
    "HS_USE_MONTH\n",
    "CURR_DEVICE_MAKER\n",
    "CURR_DEVICE_MODEL\n",
    "CURR_DEVICE_PRICE_TIER\n",
    "L1M_DEVICE_TENURE\n",
    "L1M_DEVICE_MAKER\n",
    "L1M_DEVICE_MODEL\n",
    "L1M_DEVICE_PRICE_TIER\n",
    "L1M_DEVICE_TYPE\n",
    "L2M_DEVICE_TENURE\n",
    "L2M_DEVICE_MAKER\n",
    "L2M_DEVICE_MODEL\n",
    "L2M_DEVICE_PRICE_TIER\n",
    "L2M_DEVICE_TYPE\n",
    "ZONE_ACTV_IVR_COUNTRY\n",
    "ZONE_ACTV_IVR_REGION\n",
    "STORE_TYPE\n",
    "SPAUTH_IND\n",
    "PTY_EVER_PO_CNT\n",
    "PTY_EVER_PP_CNT\n",
    "ANOTHER_ACTIVE_VD\n",
    "ANOTHER_ACTIVE_D\n",
    "PTY_CBU_EBU_PO_CNT\n",
    "PTY_CBU_PO_CNT\n",
    "PTY_CBU_PO_V_CNT\n",
    "PTY_CBU_PO_VD_CNT\n",
    "PTY_CBU_PO_D_CNT\n",
    "PTY_EBU_PO_CNT\n",
    "PTY_PO_ALL_CNT\n",
    "L6M_AVG_NET_INV_AMT\n",
    "L1M_NET_INV_AMT\n",
    "L2M_NET_INV_AMT\n",
    "W2P_SMS_MO_INT_CNT\n",
    "SMS2P_SMS_MO_CNT\n",
    "DATA_RATING_USAGE_MB\n",
    "P6M_AVG_NET_INV_AMT\n",
    "L1M_GPRS_AMT\n",
    "L2M_GPRS_AMT\n",
    "L6M_AVG_GPRS_AMT\n",
    "L6M_AVG_VAS_MB\n",
    "W2P_SMS_MO_CNT\n",
    "W2P_SMS_MO_ONNET_CNT\n",
    "W2P_SMS_MO_OFFNET_CNT\n",
    "L1M_DATA_USAGE_MB\n",
    "L2M_DATA_USAGE_MB\n",
    "P6M_AVG_DATA_USAGE_MB\n",
    "P1M_MO_ONNET_CNT\n",
    "P1M_MO_ONNET_DUR\n",
    "P1M_MO_OFFNET_CNT\n",
    "P1M_MO_OFFNET_DUR\n",
    "P1M_MO_PSTN_CNT\n",
    "P1M_MO_PSTN_DUR\n",
    "CURR_BILL_PLAN_NAME\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 因為之後telegram的會併入新的表 原本的有問題\n",
    "drop_str += telegram_str\n",
    "drop_list = drop_str.split(\"\\n\")\n",
    "drop_list = [x for x in drop_list if x != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in drop_list:\n",
    "#     try:\n",
    "#         df = df.drop(col, axis = 1)\n",
    "#     except:\n",
    "#         print(\"col = %s is not in this table\" % col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "want_cols = list(set(df.columns)-set(drop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (28,97,120,134,152,215,221,242,246,298) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read csv file and print cost time\n",
    "t0 = time.time()\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "# df = pd.read_csv(relative_filename, usecols = wants_cols, error_bad_lines=False)\n",
    "# df = pd.read_csv(relative_filename, usecols = wants_cols, error_bad_lines=False, nrows = 100000)\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "# df = pd.read_csv(relative_filename, usecols = wants_cols, sep  = '\\t', error_bad_lines=False)\n",
    "df = pd.read_sql(query_str + query_where, con)\n",
    "# df = pd.read_csv(MDS_FILE, sep  = ',', error_bad_lines=False, usecols=want_cols)\n",
    "\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "# df = pd.read_csv(relative_filename, error_bad_lines=False)\n",
    "write_to_log(\"time for read csv: %.2f\" % (time.time()-t0))\n",
    "write_to_log(\"finish read MDS csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna('?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replace space/? to random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start replace space/? to random value\")\n",
    "random_fill_str = \"\"\"\n",
    "GENDER_CODE\n",
    "IMEI_MFG_NAME\n",
    "IMEI_MKT_NAME\n",
    "ZONE_ACTIVATION_IVR\n",
    "ACTV_STORE_ID\n",
    "MOST_MO_OPERATOR\n",
    "MOST_MT_OPERATOR\n",
    "PROM_CURR_EXP_MONTH_CNT\n",
    "PROM_CURR_PROM_CODE\n",
    "\"\"\"\n",
    "random_fill_list = random_fill_str.split(\"\\n\")\n",
    "random_fill_list = [x for x in random_fill_list if x != \"\"]\n",
    "# random_fill_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question_item = [\"?\", \" \"]\n",
    "for col in random_fill_list:\n",
    "    for q_item in question_item:\n",
    "        q_item_count = len(df[df[col] == q_item])\n",
    "#         print(\"'\"+ q_item + \"' count =\", q_item_count)\n",
    "        if q_item_count > 0:\n",
    "            sample_list = df[df[col] != q_item].sample(q_item_count)\n",
    "            df.loc[df[df[col] == q_item].index, col] = sample_list[col].values\n",
    "#     print(\"? count =\", len(df[df[col] == \"?\"]))\n",
    "#     print(\"space count =\", len(df[df[col] == \" \"]))\n",
    "#     print(col, \"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill up the specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specific_fill_str = \"\"\"\n",
    "# PROM_CURR_PROMOTION_TYPE\n",
    "# PROM_CURR_PROMOTION_SUB_TYPE\n",
    "# PROM_ACTV_PROM_SUB_TYPE\n",
    "# LAST_CHANNEL_TYPE\n",
    "# IMEI_BAND\n",
    "# IMEI_TYPE\n",
    "# \"\"\"\n",
    "# specific_fill_str = specific_fill_str.split(\"\\n\")\n",
    "# specific_fill_list = [x for x in specific_fill_list if x != \"\"]\n",
    "# specific_fill_list\n",
    "write_to_log(\"start fill up the specific value\")\n",
    "\n",
    "specific_dict = {\n",
    "    \"PROM_CURR_PROMOTION_TYPE\" : \"others\",\n",
    "    \"PROM_CURR_PROMOTION_SUB_TYPE\" : \"others\",\n",
    "    \"PROM_ACTV_PROM_SUB_TYPE\" : \"others\",\n",
    "    \"LAST_CHANNEL_TYPE\" : \"others\",\n",
    "    \"IMEI_TYPE\" : \"Smart Phone\",\n",
    "    \"VIP_TENURE\" : 0,\n",
    "    \"P3M_MO_PSTN_DUR\" : 0,\n",
    "    \"HS_CHG_CNT\" : 0,\n",
    "    \"AVG_HS_USE_MONTH_EX_CURR\" : 0,\n",
    "    \"PAY_PENALTY_AMT\" : 0,\n",
    "    \"P3M_AVG_DATA_USAGE_MB\" : 0,\n",
    "    \"P3M_MO_ONNET_CNT\" : 0,\n",
    "    \"P3M_MO_ONNET_DUR\" : 0,\n",
    "    \"P3M_MO_OFFNET_CNT\" : 0,\n",
    "    \"P3M_MO_OFFNET_DUR\" : 0,\n",
    "    \"P3M_MO_PSTN_CNT\" : 0,\n",
    "    \"AVG_HS_USE_MONTH\" : 0\n",
    "#     \"跟價格有關的負數補0\" : 0\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col, value in specific_dict.items():\n",
    "    df.loc[df[df[col] == \"?\"].index, col] = value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMEI_BAND fill up 3G or 4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start IMEI_BAND fill up 3G or 4G\")\n",
    "col = \"IMEI_BAND\"\n",
    "q_item_count = len(df[df[col] == \"?\"])\n",
    "sample_list = df[(df[col] == \"3G\") | (df[col] == \"4G\")].sample(q_item_count)\n",
    "df.loc[df[df[col] == \"?\"].index, col] = sample_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:ORIG_OPR_ID merge telegram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPR_ID_dict = {\n",
    "    \"QWR\" : \"遠傳電信\",\n",
    "    \"QW3\" : \"遠傳電信\",\n",
    "    \"ARC\" : \"遠傳電信\",\n",
    "    \"AMT\" : \"亞太電信\",\n",
    "    \"AP4\" : \"亞太電信\",\n",
    "    \"APT\" : \"亞太電信\",\n",
    "    \"APW\" : \"亞太電信\",\n",
    "    \"CH3\" : \"中華電信\",\n",
    "    \"CH4\" : \"中華電信\",\n",
    "    \"CHM\" : \"中華電信\",\n",
    "    \"CHT\" : \"中華電信\",\n",
    "    \"FE4\" : \"遠傳電信\",\n",
    "    \"FET\" : \"遠傳電信\",\n",
    "    \"KGT\" : \"遠傳電信\",\n",
    "    \"MBT\" : \"台灣大哥大\",\n",
    "    \"SPQ\" : \"遠傳電信\",\n",
    "    \"TAT\" : \"台灣大哥大\",\n",
    "    \"TFN\" : \"台灣大哥大\",\n",
    "    \"TSC\" : \"台灣之星\",\n",
    "    \"TW3\" : \"台灣大哥大\",\n",
    "    \"TW4\" : \"台灣大哥大\",\n",
    "    \"TWM\" : \"台灣大哥大\",\n",
    "    \"VBT\" : \"台灣之星\",\n",
    "    \"YZT\" : \"台灣之星\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = \"ORIG_OPR_ID\"\n",
    "# d = dict(zip(unique_list, values))\n",
    "df[col] = df[col].map(OPR_ID_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[col] = df[col].fillna(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補眾數欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = \"BILL_CITY_NAME\"\n",
    "df.loc[df[df[col] == \"?\"].index, col] = df[col].describe().top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = \"AGENCY_FLAG\"\n",
    "df.loc[df[df[col] == \"?\"].index, col] = df[col].describe().top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = \"AGE\"\n",
    "avg = sum(df[df[col] != \"?\"][col].apply(np.int64)) / len(df[df[col] != \"?\"])\n",
    "df.loc[df[df[col] == \"?\"].index, col] = avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMT 如果是負數的話 補0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if(col.endswith(\"AMT\")):\n",
    "#         print(col)\n",
    "#         print(df[col].describe())\n",
    "        try:\n",
    "            df[col] = df[col].apply(np.float64)\n",
    "            df.loc[df[df[col] < 0].index, col] = 0\n",
    "        except:\n",
    "            write_to_log(\"this col => %s no only value\" % col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop VAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start drop vas\")\n",
    "df = df.drop('VAS_AMT', axis = 1)\n",
    "df = df.drop('L3M_AVG_VAS_MB', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine 3大2小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start combine 3大2小\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telegram_df = pd.read_csv(TELEGRAM_MT_FILE, error_bad_lines=False)\n",
    "telegram_df = telegram_df.drop(\"DATA_MONTH\", axis = 1)\n",
    "try:\n",
    "    telegram_df = telegram_df.drop(\"DATA_MONTH\", axis = 1)\n",
    "except:\n",
    "    write_to_log(\"telegram_mt_df  no month\")\n",
    "df = pd.merge(df, telegram_df, on='MINING_DW_SUBSCR_NO', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_df = pd.read_csv(TELEGRAM_MO_FILE, error_bad_lines=False)\n",
    "try:\n",
    "    telegram_df = telegram_df.drop(\"DATA_MONTH\", axis = 1)\n",
    "except:\n",
    "    write_to_log(\"telegram_mo_df  no month\")\n",
    "df = pd.merge(df, telegram_df, on='MINING_DW_SUBSCR_NO', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 語音 mo + mt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_log(\"start combine CWC\")\n",
    "month_col_name = \"DATA_MONTH\"\n",
    "query_str = \"sel * from CSM_PROJECT.\" + \"CWC_CATG_CNT_VW\"\n",
    "if len(month) == 1:\n",
    "    query_where = ' where  DATA_MONTH = ' + year + '0' + month\n",
    "else:\n",
    "    query_where = ' where  DATA_MONTH = ' + year + month\n",
    "\n",
    "cwc_df = pd.read_sql(query_str + query_where, con)\n",
    "# cwc_df = pd.read_csv(CWC_FILE, error_bad_lines=False)\n",
    "# cwc_df = cwc_df[cwc_df[\"DATA_MONTH\"] == int(DATA_MONTH)]\n",
    "cwc_df = cwc_df.drop(\"CURR_SUBSCR_ID\", axis = 1)\n",
    "cwc_df = cwc_df.drop(\"DATA_MONTH\", axis = 1)\n",
    "\n",
    "# if(\"Groups\" in list(df.columns)):\n",
    "#     df = df.drop(\"Groups\", axis = 1)\n",
    "df = pd.merge(df, cwc_df, on='MINING_DW_SUBSCR_NO', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer to 相等深度(Equal-Frequency-Interval)裝箱法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tranferEFI(df_col, div_num = 3):\n",
    "    return pd.qcut(df_col, div_num, labels=[\"L\",\"M\",\"H\"], retbins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qcut_info = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: array([ nan,  nan,  nan,  nan])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6871eb26a9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mq_cut_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'DATA_USAGE_MB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MOC_DUR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MTC_DUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mq_cut_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranferEFI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mqcut_info\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcut_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-941b994bea43>\u001b[0m in \u001b[0;36mtranferEFI\u001b[0;34m(df_col, div_num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtranferEFI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"M\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"H\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\simslab\\Anaconda3\\lib\\site-packages\\pandas\\tools\\tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     return _bins_to_cuts(x, bins, labels=labels, retbins=retbins,\n\u001b[0;32m--> 175\u001b[0;31m                          precision=precision, include_lowest=True)\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\simslab\\Anaconda3\\lib\\site-packages\\pandas\\tools\\tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, retbins, precision, name, include_lowest)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bin edges must be unique: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([ nan,  nan,  nan,  nan])"
     ]
    }
   ],
   "source": [
    "q_cut_cols = ['DATA_USAGE_MB', 'MOC_DUR', 'MTC_DUR']\n",
    "for col in q_cut_cols:\n",
    "    df[col], cut_info = tranferEFI(df[col])\n",
    "    qcut_info += col + \"\\n\" +str(cut_info) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./marketing_q_cut.txt\", \"w\") as text_file:\n",
    "    text_file.write(qcut_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 0804信件說要刪除的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start drop some cols\")\n",
    "mail_say_delete_str = \"\"\"\n",
    "DATA_RC_AMT\n",
    "L1M_DATA_MONTHLY_FEE\n",
    "MO_OFFNET_DUR\n",
    "MO_ONNET_DUR\n",
    "MOC_PSTN_DUR\n",
    "MTC_CNT\n",
    "NET_INV_AMT\n",
    "VOICE_RC_AMT\n",
    "\"\"\"\n",
    "drop_list = mail_say_delete_str.split(\"\\n\")\n",
    "drop_list = [x for x in drop_list if x != \"\"]\n",
    "want_cols = list(set(df.columns)-set(drop_list))\n",
    "df = df[want_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start load GROUP ID FILE\")\n",
    "group_df = pd.read_csv(GROUP_ID_FILE, error_bad_lines=False, usecols = [\"MINING_DW_SUBSCR_NO\", \"Groups\"])\n",
    "if(\"Groups\" in list(df.columns)):\n",
    "    df = df.drop(\"Groups\", axis = 1)\n",
    "df = pd.merge(df, group_df, on='MINING_DW_SUBSCR_NO', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv(path + out_filename + \"with_id.csv\", index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_log(\"start drop MINING_DW_SUBSCR_NO\")\n",
    "df = df.drop(\"MINING_DW_SUBSCR_NO\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file %s mrk_picked_with_group_id.csv\n"
     ]
    }
   ],
   "source": [
    "write_to_log(\"start output file %s\" % OUT_FILENAME)\n",
    "print(\"output file %s\", OUT_FILENAME)\n",
    "\n",
    "t0 = time.time()\n",
    "df.to_csv(OUT_FILENAME, index=False, encoding='utf-8')\n",
    "write_to_log(\"time for output csv file: %.2f\" % (time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish marketing_filter_columns\n"
     ]
    }
   ],
   "source": [
    "print(\"finish marketing_filter_columns.py\")\n",
    "write_to_log(\"finish marketing_filter_columns.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from mailerWithUtf8 import mail\n",
    "# test=mail()\n",
    "# test.main(\"finished\", \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Clear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather \n",
    "import matplotlib.pyplot as plt  \n",
    "from time import time\n",
    "from mailerWithUtf8 import mail\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(df, out_filename):\n",
    "   # write to csv and no index\n",
    "    t0 = time()\n",
    "    df.to_csv(out_filename + \".csv\", index=False, encoding='utf-8')\n",
    "#     df.to_csv(out_filename + \".csv\", encoding='utf-8')\n",
    "    print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feather %s seconds 41.47628569602966\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "path = \"C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/\"\n",
    "# filename = '0713_april_marketing_anylze_full_table_group12_select_max_min.feather' \n",
    "filename = \"0725_april_marketing_anylze_select_294_table_group11_max_min.csv\"\n",
    "# train_df = feather.read_dataframe(path + filename)\n",
    "train_df = pd.read_csv(path + filename, error_bad_lines=False)\n",
    "\n",
    "print('load feather %s seconds', format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0725_april_marketing_anylze_select_294_table_group11_max_min_test.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9ceafe869b08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# test_df = feather.read_dataframe(path + filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0725_april_marketing_anylze_select_294_table_group11_max_min_test.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load feather %s seconds'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0725_april_marketing_anylze_select_294_table_group11_max_min_test.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# filename = '0713_april_marketing_anylze_full_table_group12_max_min_test.feather' \n",
    "# filename = '0713_april_marketing_anylze_full_table_group12_select_max_min_test.feather' \n",
    "# filename = '0713_april_marketing_anylze_full_table_group12_max_min.feather' \n",
    "\n",
    "# test_df = feather.read_dataframe(path + filename)\n",
    "filename = \"0725_april_marketing_anylze_select_294_table_group11_max_min_test.csv\"\n",
    "test_df = pd.read_csv(path + filename, error_bad_lines=False)\n",
    "\n",
    "print('load feather %s seconds', format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Groups'] != 'Infrequent_User']\n",
    "test_df = test_df[test_df['Groups'] != 'Infrequent_User']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df = train_df[wants_col]\n",
    "# test_df = test_df[wants_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSIFIER = \"RANDOM_FOREST\"\n",
    "CURRENT_MODE = \"SELECT_MODE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = train_df[\"Groups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_filename = CLASSIFIER + \"_\" + CURRENT_MODE + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = \"clf_random_forest_model_kFold/all/\" \n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x, test_y = test_df.iloc[:, 0:-1].values, test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert y to numeric# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_df[\"Groups\"].unique())\n",
    "train_numeric_y = le.transform(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_numeric_y = le.transform(test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                            oob_score=True,\n",
    "                            random_state=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_estimators = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\" : [\"gini\"], \n",
    "              \"min_samples_leaf\" : [10], \n",
    "              \"min_samples_split\" : [2],\n",
    "#               \"max_depth\" : [10],\n",
    "              \"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_clf = gs.fit(train_x, train_numeric_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(clf, out_path + out_filename + 'CLF.pkl') \n",
    "# clf = joblib.load('filename.pkl') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_info = str((\"Accuracy on training set: %f\" % grid_clf.score(train_x, train_numeric_y))) + '\\n'\n",
    "clf_info += str((\"Accuracy on test set: %f\" % clf.score(test_x, test_numeric_y))) + '\\n'\n",
    "clf_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "print(clf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(698, 350) \n",
    "Beep(523, 150) \n",
    "Beep(415, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "test=mail()\n",
    "test.main(\"clf_info finished\", clf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numeric_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_dict = dict(zip(train_df.columns[:-1],clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list = sorted(important_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_info += '\\n\\nFeature Importances\\n===================\\n'\n",
    "for row in important_list:\n",
    "    clf_info += str(row) + \"\\n\"\n",
    "    print(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(important_list, columns = [\"COLUMN\", \"IMPORTANT_VALUE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "feature_df.to_csv(out_path + out_filename + \"feature_important_descent.csv\", index=False)\n",
    "print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cpy_dict = dict(important_list)\n",
    "# # cpy_dict[\"Groups\"] = target_groups\n",
    "# feature_df = pd.DataFrame(cpy_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# feature_df.to_csv(out_path + out_filename + \"feature_important_one_row.csv\", index=False)\n",
    "# print(\"time for output csv file: %.2f\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_numeric_y, predict_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "    idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    clf_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd = pd.DataFrame(cnf_matrix)\n",
    "cnf_pd.columns = group_encoder\n",
    "cnf_pd.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_info = clf_info.replace(\"\\n\", \"<br>\")\n",
    "with open(out_path + out_filename + 'readme.md', 'w+') as f:\n",
    "     f.write(md_info)\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(698, 350) \n",
    "Beep(523, 150) \n",
    "Beep(415, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.feature_importances_, 'o')  \n",
    "# for i in \n",
    "plt.xticks(range(train_x.shape[1]), train_df.columns[:-1], rotation=90)  \n",
    "plt.ylim(0, 1)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check feature importances accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "limit_importances = 5\n",
    "for idx, feature in enumerate(important_list):\n",
    "    if(idx == limit_importances):\n",
    "        break\n",
    "\n",
    "    #     print(feature[0])\n",
    "    feature_cols.append(feature[0])\n",
    "feature_cols.append(\"Groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train_x = train_df[feature_cols].iloc[:, 0:-1].values\n",
    "feature_test_x = test_df[feature_cols].iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_feature = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_feature_clf = gs_feature.fit(feature_train_x, train_numeric_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_feature = grid_feature_clf.best_estimator_\n",
    "clf_feature_info = str((\"Accuracy on training set: %f\" % clf_feature.score(feature_train_x, train_numeric_y))) + '\\n'\n",
    "clf_feature_info += str((\"Accuracy on test set: %f\" % clf_feature.score(feature_test_x, test_numeric_y))) + '\\n'\n",
    "clf_feature_info += str(('fit time %s seconds' % format(time() - start_time))) + '\\n'\n",
    "clf_feature_info += str(('feature selection numbers = %s' % str(limit_importances) + '\\n'\n",
    "\n",
    "print(clf_feature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_feature_y = clf_feature.predict(feature_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_numeric_y, predict_feature_y )\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_encoder = []\n",
    "for idx, row in enumerate(cnf_matrix):\n",
    "#     success predict\n",
    "#     print(row[idx])\n",
    "    current_group = str(le.inverse_transform(idx))\n",
    "    group_encoder.append(current_group)\n",
    "#     current_group = groups[idx]\n",
    "\n",
    "    print(current_group)\n",
    "\n",
    "    idx_count_in_group = len(test_df[test_df[\"Groups\"] == current_group])\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"class = %s count = [%s / %s]\" % (current_group, row[idx], idx_count_in_group))\n",
    "    clf_feature_info +=  \"\\n\\n\" + str(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print(\"class = %s count = [%s / %s]\" % (current_group,row[idx],str(idx_count_in_group)))\n",
    "    print(\"predict %s accurancy = %s\" % (current_group, row[idx] / idx_count_in_group))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd = pd.DataFrame(cnf_matrix)\n",
    "cnf_pd.columns = group_encoder\n",
    "cnf_pd.index = group_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(659, 500) \n",
    "Beep(698, 350) \n",
    "Beep(523, 150) \n",
    "Beep(415, 500) \n",
    "Beep(349, 350) \n",
    "Beep(523, 150) \n",
    "Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mail_info = clf_feature_info.replace(\"\\n\", \"<br>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mail_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mailerWithUtf8 import mail\n",
    "test=mail()\n",
    "test.main(\"clf_info finished\", mail_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
